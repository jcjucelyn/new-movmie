{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13339af6-b0df-4484-9c58-b52cb0e63821",
   "metadata": {},
   "source": [
    "# Import the Necessary Libraries/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ba681-d8f7-4a95-8d07-6c1da91ba616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries/packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e62a4-cd35-45e8-8835-c69330ba5032",
   "metadata": {},
   "source": [
    "# Load the Necessary Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2b33d-03d2-470c-8b1a-f187968f75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MovieLens data sets\n",
    "full_data = pd.read_csv(\"u.data\", \n",
    "                        names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n",
    "                        sep=\"\\t\",\n",
    "                        header=None)\n",
    "\n",
    "item_data = pd.read_csv(\"u.item\",\n",
    "                        names=[\"movie_id\", \"movie_title\", \"release_date\", \"video_release_date\", \"IMDb_url\", \"unknown\",\n",
    "                               \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\",\n",
    "                               \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\",\n",
    "                               \"Western\"],\n",
    "                        sep=\"|\",\n",
    "                        header=None,\n",
    "                        encoding=\"latin-1\")\n",
    "\n",
    "user_data = pd.read_csv(\"u.user\",\n",
    "                        names=[\"u_id\", \"age\", \"gender\", \"occupation\", \"zip_code\"],\n",
    "                        sep=\"|\",\n",
    "                        header=None,\n",
    "                        encoding=\"latin-1\")\n",
    "\n",
    "print(f\"The first 5 rows of u.data:\\n {full_data.head()}\")\n",
    "print(\" \")\n",
    "print(f\"The first 5 rows of u.item:\\n {item_data.head()}\")\n",
    "print(\" \")\n",
    "print(f\"The first 5 rows of u.user:\\n {user_data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88665f0-10a4-448c-929c-a41547d7e547",
   "metadata": {},
   "source": [
    "# Merge the Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b46580-d766-45f8-bd2d-e38065c7e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge full_data and item_data by item/movie id\n",
    "full_item_merged = pd.merge(full_data, item_data, left_on=\"item_id\", right_on=\"movie_id\")\n",
    "full_item_merged = full_item_merged.drop(\"movie_id\", axis=1)\n",
    "\n",
    "# Merge full_item_merged and user_data by user id\n",
    "final_merged = pd.merge(full_item_merged, user_data, left_on=\"user_id\", right_on=\"u_id\")\n",
    "final_merged = final_merged.drop(\"u_id\", axis=1)\n",
    "\n",
    "print(final_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2dae0",
   "metadata": {},
   "source": [
    "# Drop the user_id and item_id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2090424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop user_id and item_id\n",
    "final_merged_clean = final_merged.drop([\"user_id\", \"item_id\"], axis=1)\n",
    "print(final_merged_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9944de-7cd3-4d4f-855d-4d7ebe93d49a",
   "metadata": {},
   "source": [
    "# Identify Features with Missing Data, and Drop Those Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608b14d-33ba-429a-8b96-be3851541c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features with missing data\n",
    "print(final_merged_clean.isnull().sum())\n",
    "print(\" \")\n",
    "\n",
    "# Drop release_date, video_release_date, and IMDb_url\n",
    "final_merged_clean = final_merged_clean.drop([\"release_date\", \"video_release_date\", \"IMDb_url\"], axis=1)\n",
    "print(final_merged_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f9e67-7008-482f-9650-b4f79c7b4ef9",
   "metadata": {},
   "source": [
    "My though process is, we don't want to sacrifice any ratings/movies/users from the dataset, but when predicting the ratings using all the input features, we don't want features with missing values because those missing values would have to be deleted/imputed/otherwise dealt with, which would potentially mess with the the integrity of the features themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d312c-fc79-4526-892e-a4861a7001c9",
   "metadata": {},
   "source": [
    "# Add an Intercept/Bias Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4a576-9b92-4ba8-b3da-dee1fa830e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an additional intercept/bias column to the dataset\n",
    "final_merged_clean[\"bias\"] = 1\n",
    "final_merged_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978809ab-68ae-4219-84ca-b2a2cbe6a27d",
   "metadata": {},
   "source": [
    "# Gauge Feature Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6b0cd-0b80-46e4-8157-cd1dd0a71012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauge the features' data types\n",
    "print(final_merged_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78560b5b-d20f-4880-a850-0d70b97674eb",
   "metadata": {},
   "source": [
    "The one feature I was going back-and-forth with in terms of keeping it categorical vs. numerical was zip_code, but after doing some research, I decided to keep it categorical because the numbers in a particular zip code are symbolic and don't assume any significant value.\n",
    "\n",
    "Besides, some zip codes contain letters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361f6b9-4048-4ba4-9c8e-34dba60c1088",
   "metadata": {},
   "source": [
    "# Perform One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07deac-7cd7-4923-80d2-d6d713f9a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical features for the full dataset\n",
    "onehot_movie = pd.get_dummies(final_merged_clean, drop_first=True, dtype=int)\n",
    "onehot_movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17450729-47ed-4df1-8e39-9537b15e9807",
   "metadata": {},
   "source": [
    "# Transform the Data into a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63152583-e190-4461-a0cf-3145ee19e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the encoded data into a NumPy Array for ML purposes\n",
    "onehot_movie = onehot_movie.to_numpy()\n",
    "onehot_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f32f5f-3c94-4e56-8840-5ab899a00853",
   "metadata": {},
   "source": [
    "# Perform Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd6fc3-fab1-44ef-9581-171680a63f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all features except rating using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "onehot_movie_scale = scaler.fit_transform(onehot_movie[:, 1:]).round(2)\n",
    "onehot_movie_scale_final = np.column_stack((onehot_movie_scale, full_data[\"rating\"].values))\n",
    "onehot_movie_scale_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b62524-6948-48a4-a6fd-7793a72ba1fc",
   "metadata": {},
   "source": [
    "# Separate the Data into its Input Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc16983-3b28-4f64-8b9d-3fe42c49d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into input features and target\n",
    "X = onehot_movie_scale_final[:, :-1]\n",
    "y = onehot_movie_scale_final[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6912d-d4de-475d-ad2a-6bb148ca8bc8",
   "metadata": {},
   "source": [
    "# Implement a Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652192d7-0455-4e64-89c3-ebaad3b31fdb",
   "metadata": {},
   "source": [
    "## Implement a Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc7804-7600-4041-851b-89faeaa314da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a random seed to maintain the same values in the weight matrices\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e81dd-3c93-4226-90f5-27ca4babe2b2",
   "metadata": {},
   "source": [
    "## Define the Features, Target, Step Size, Weight Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ce53e-6397-42ce-88da-832666dbf23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X\n",
    "\n",
    "y = y\n",
    "eta = 0.1\n",
    "\n",
    "W1 = np.random.randn(2500,10)\n",
    "W2 = np.random.randn(10,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d8cf2-ad83-4b70-b052-f6425be645e8",
   "metadata": {},
   "source": [
    "## Define the Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d3086-fef5-4aef-b447-8861dd5eb7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the ReLU activation function for h and the sigmoid activation function for the output\n",
    "def f(x):\n",
    "    h = np.maximum(0, W1.T.dot(x))\n",
    "    return 1 / (1 + np.exp(-W2.T.dot(h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c9cc1-a676-432a-8447-6ad22365a8ac",
   "metadata": {},
   "source": [
    "## Monitor Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88498b2b-2b55-4a41-9082-528c1cd9cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Best to run on Northeastern Cluster (takes a while to run)\n",
    "# Keep track of gradient descent errors to monitor convergence\n",
    "errors = []\n",
    "\n",
    "# Instantiate a number of iterations/epochs to run the algorithm for\n",
    "epochs = 500\n",
    "\n",
    "# Obtain the number of nodes of the input layer\n",
    "n = X.shape[0]\n",
    "\n",
    "# Iterate over the number of iterations/epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Calculate the derivative with respect to w^(2)\n",
    "    dW2 = 0\n",
    "    for i, j in enumerate(y):\n",
    "        x = np.reshape(X[i], (2500,1))\n",
    "        h = np.maximum(0, W1.T.dot(x))\n",
    "        dW2 += (1/n) * (f(x) - y[i])*h\n",
    "\n",
    "    # Update w^(2) using the old value of w^(2) and the current values of h\n",
    "    W2 = W2 - eta * dW2\n",
    "\n",
    "    # Calculate the derivative with respect to W^(1)\n",
    "    dW1 = 0\n",
    "    for i, j in enumerate(y):\n",
    "        x = np.reshape(X[i], (2500,1))\n",
    "        h = np.maximum(0, W1.T.dot(x))\n",
    "        mat1 = np.heaviside(h, 0)\n",
    "\n",
    "        dW1 += (1/n) * np.kron((((f(x) - y[i])*W2) * mat1).T, x)\n",
    "\n",
    "    # Update W^(1) using the old value of W^(1) and the current values of h\n",
    "    W1 = W1 - eta * dW1\n",
    "\n",
    "    # Calculate the gradient descent error\n",
    "    e = (1/n) * np.sum((-y*np.log(f(X.T))) - ((1 - y)*np.log(1 - f(X.T))))\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11baf9a4-38b9-4103-9c9e-fc77cfdd84f0",
   "metadata": {},
   "source": [
    "## Display the Final Weight Estimates and Predicted Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb86575-7696-443f-a4df-dcd09c28cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final estimate of W^(1)\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d2eac-703d-4152-9516-46015f8dba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final estimate of w^(2)\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536a437-047c-423d-87d2-96f08537306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final predicted output\n",
    "print(f(X.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2e126-9fb5-454f-aa71-7e8041274b20",
   "metadata": {},
   "source": [
    "## Visualize the Gradient Descent Errors vs. Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fbaf1e-a803-4564-934b-e1767d67e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line plot visualizing the gradient descent errors as a function of the number of epochs\n",
    "plt.plot(range(42), errors, label=\"line\")\n",
    "plt.xlim(0, 42)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim(0, 1.5)\n",
    "plt.ylabel(\"Gradient Descent Errors\")\n",
    "plt.title(\"Multilayer Perceptron (MLP) Convergence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9a30d-d847-417d-906c-0453d924e5af",
   "metadata": {},
   "source": [
    "## Predict the Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2f9a7-d237-4ca0-b4fa-ef4f608cb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the data\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,), activation=\"relu\", learning_rate_init=0.01, max_iter=500, random_state=12).fit(X, y)\n",
    "preds = clf.predict(X)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63010f4b-4feb-4e18-97bc-20ed235e702b",
   "metadata": {},
   "source": [
    "## Evaluate the MLP's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175ab52-40a0-40a6-ac21-5c88848b47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the algorithm\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98781ed2-ce20-4b94-97d7-f0c6cf683e42",
   "metadata": {},
   "source": [
    "# Gather the Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d78d1-44c8-4c0a-adae-519e8c1412c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain user id-item id-predicted movie rating combinations\n",
    "data = {\"user_id\": final_merged[\"user_id\"], \"item_id\": final_merged[\"item_id\"], \"predicted_rating\": preds}\n",
    "\n",
    "final_df = pd.DataFrame(data=data)\n",
    "\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the resulting DataFrame as a .csv file\n",
    "final_df.to_csv(\"mlp_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375392c2-06c2-4b2f-b8f7-0e72b62f4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the .csv file of predicted ratings\n",
    "pred_ratings = pd.read_csv(\"data/mlp_results.csv\")\n",
    "pred_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226c8b2-ad3c-4093-aec6-14be7e224171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the predicted ratings match the ratings from the original MovieLens data\n",
    "print(pred_ratings[\"predicted_rating\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160610b-689e-48ab-9c2c-144a5a33ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted ratings vs. original ratings\n",
    "plt.figure()\n",
    "plt.scatter(pred_ratings[\"predicted_rating\"], full_data[\"rating\"])\n",
    "plt.xlabel(\"MLP Predicted Movie Rating\")\n",
    "plt.ylabel(\"True Movie Rating\")\n",
    "plt.title(\"MLP Predictions vs. True Values for Movie Rating\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
